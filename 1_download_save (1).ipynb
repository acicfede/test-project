{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Save the Model\n",
    "\n",
    "To save this model so that you can use it from various locations, including other notebooks or the model server, upload it to s3-compatible storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install the required packages and define a function for the upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/app-root/lib/python3.9/site-packages (1.34.150)\n",
      "Requirement already satisfied: botocore in /opt/app-root/lib/python3.9/site-packages (1.34.150)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/app-root/lib/python3.9/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib/python3.9/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib/python3.9/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/app-root/lib/python3.9/site-packages (from botocore) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Download from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'flan-t5-small'...\n",
      "remote: Enumerating objects: 62, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 62 (delta 25), reused 18 (delta 18), pack-reused 32 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (62/62), 620.61 KiB | 1.03 MiB/s, done.\n",
      "Filtering content: 100% (5/5), 1.27 GiB | 330.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/google/flan-t5-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=aws_access_key_id,\n",
    "                                aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name)\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "#upload the model directory without git\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            if \".git\" in relative_path:\n",
    "                continue\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check the Storage Bucket\n",
    "\n",
    "In your S3 bucket, under the `models` upload prefix, run the `list_object` command. As best practice, to avoid mixing up model files, keep only one model and its required files in a given prefix or directory. This practice allows you to download and serve a directory with all the files that a model requires. \n",
    "\n",
    "If this is the first time running the code, this cell will have no output or the fraud model from the predictive AI/ML exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/flan-t5-small/README.md\n",
      "models/flan-t5-small/config.json\n",
      "models/flan-t5-small/generation_config.json\n",
      "models/flan-t5-small/special_tokens_map.json\n",
      "models/flan-t5-small/spiece.model\n",
      "models/flan-t5-small/tokenizer.json\n",
      "models/flan-t5-small/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "list_objects(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload and check again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function to upload the `models` folder in a rescursive fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-small/flax_model.msgpack -> models/flan-t5-small/flax_model.msgpack\n",
      "flan-t5-small/tokenizer.json -> models/flan-t5-small/tokenizer.json\n",
      "flan-t5-small/spiece.model -> models/flan-t5-small/spiece.model\n",
      "flan-t5-small/tokenizer_config.json -> models/flan-t5-small/tokenizer_config.json\n",
      "flan-t5-small/special_tokens_map.json -> models/flan-t5-small/special_tokens_map.json\n",
      "flan-t5-small/pytorch_model.bin -> models/flan-t5-small/pytorch_model.bin\n",
      "flan-t5-small/config.json -> models/flan-t5-small/config.json\n",
      "flan-t5-small/README.md -> models/flan-t5-small/README.md\n",
      "flan-t5-small/tf_model.h5 -> models/flan-t5-small/tf_model.h5\n",
      "flan-t5-small/generation_config.json -> models/flan-t5-small/generation_config.json\n",
      "flan-t5-small/model.safetensors -> models/flan-t5-small/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "upload_directory_to_s3(\"flan-t5-small\", \"models/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To confirm this worked, run the `list_objects` function again:\n",
    "\n",
    "This time, you should see files listed in the directory/prefix: `models/flan-t5-small`\n",
    "\n",
    "```\n",
    "models/flan-t5-small/README.md\n",
    "models/flan-t5-small/config.json\n",
    "models/flan-t5-small/flax_model.msgpack\n",
    "models/flan-t5-small/generation_config.json\n",
    "models/flan-t5-small/model.safetensors\n",
    "models/flan-t5-small/pytorch_model.bin\n",
    "models/flan-t5-small/special_tokens_map.json\n",
    "models/flan-t5-small/spiece.model\n",
    "models/flan-t5-small/tf_model.h5\n",
    "models/flan-t5-small/tokenizer.json\n",
    "models/flan-t5-small/tokenizer_config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/flan-t5-small/README.md\n",
      "models/flan-t5-small/config.json\n",
      "models/flan-t5-small/flax_model.msgpack\n",
      "models/flan-t5-small/generation_config.json\n",
      "models/flan-t5-small/model.safetensors\n",
      "models/flan-t5-small/pytorch_model.bin\n",
      "models/flan-t5-small/special_tokens_map.json\n",
      "models/flan-t5-small/spiece.model\n",
      "models/flan-t5-small/tf_model.h5\n",
      "models/flan-t5-small/tokenizer.json\n",
      "models/flan-t5-small/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "list_objects(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "\n",
    "Now that you've saved the model to s3 storage, you can refer to the model by using the same data connection to serve the model as an API.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
